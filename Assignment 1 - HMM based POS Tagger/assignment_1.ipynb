{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "nltk_data = list(nltk.corpus.brown.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = [tup for sent in nltk_data for tup in sent]\n",
    "tags = {tag for word, tag in tagged_words}\n",
    "\n",
    "word_tag_freq = defaultdict(lambda: defaultdict(int))\n",
    "tag_count = defaultdict(int)\n",
    "       \n",
    "for word, tag in tagged_words:\n",
    "    word_tag_freq[word][tag] += 1\n",
    "    tag_count[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, tags_seq):\n",
    "    transitions = defaultdict(int)\n",
    "    tag_seq_len = len(tags_seq)\n",
    "\n",
    "    for i in range(tag_seq_len - 1):\n",
    "        if tags_seq[i] == t1 and tags_seq[i + 1] == t2:\n",
    "            transitions[(t1, t2)] += 1\n",
    "\n",
    "    count_t1 = tags_seq.count(t1)\n",
    "    return transitions[(t1, t2)] / count_t1 if count_t1 > 0 else 1e-6\n",
    "\n",
    "# Emission probabilities for word given tag\n",
    "def word_given_tag(word, tag):\n",
    "    count_tag = tag_count[tag]\n",
    "    count_word_tag = word_tag_freq[word][tag] if word in word_tag_freq else 0\n",
    "    return count_word_tag / count_tag if count_tag > 0 else 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Cross-Validation Accuracy: 96.10%\n",
      "\n",
      "Confusion Matrix:\n",
      "          ADP       .     X    NUM    ADV   CONJ    NOUN    ADJ     DET   PRON  \\\n",
      "ADP   135351      20     5      1   1119    148      48     95     201      0   \n",
      ".          0  147565     0      0      0      0       0      0       0      0   \n",
      "X         24      24  1158      5      4      4     109      7      17      5   \n",
      "NUM        0       0     0  14670      0      0     204      0       0      0   \n",
      "ADV     2668       0     1      0  48879    124     100   3212     373      0   \n",
      "CONJ       3       0     0      0     55  37965       2      0     126      0   \n",
      "NOUN      33       1    18    543    132      1  269008   2793     115     16   \n",
      "ADJ       80       0     3      4   2303      0    1839  78935       0      0   \n",
      "DET     1161       0     5      2      2     37       1      0  135566    244   \n",
      "PRON    1776       0     0      0      3      0       0      0    1139  46414   \n",
      "VERB     162       0     5      0     99      0    5300    477       0      0   \n",
      "PRT     5681       0     0      0    105      0      91    292       2     12   \n",
      "\n",
      "        VERB    PRT  \n",
      "ADP       97   7681  \n",
      ".          0      0  \n",
      "X         27      2  \n",
      "NUM        0      0  \n",
      "ADV       22    860  \n",
      "CONJ       0      0  \n",
      "NOUN    2858     40  \n",
      "ADJ      327    230  \n",
      "DET        0      1  \n",
      "PRON       0      2  \n",
      "VERB  176692     15  \n",
      "PRT       28  23618  \n",
      "\n",
      "Per POS Tag Accuracy:\n",
      "ADP: 93.50%\n",
      ".: 100.00%\n",
      "X: 83.55%\n",
      "NUM: 98.63%\n",
      "ADV: 86.91%\n",
      "CONJ: 99.51%\n",
      "NOUN: 97.62%\n",
      "ADJ: 94.28%\n",
      "DET: 98.94%\n",
      "PRON: 94.08%\n",
      "VERB: 96.69%\n",
      "PRT: 79.18%\n"
     ]
    }
   ],
   "source": [
    "# Optimized Viterbi Algorithm with smoothing for unknown words\n",
    "def Viterbi_optimized(words, tags_df, train_tagged_words):\n",
    "    state = []\n",
    "    T = list(tag_count.keys())\n",
    "    word_prob_cache = {}\n",
    "\n",
    "    for key, word in enumerate(words):\n",
    "        p = []\n",
    "        if word in word_tag_freq:\n",
    "            possible_tags = list(word_tag_freq[word].keys())\n",
    "        else:\n",
    "            possible_tags = T\n",
    "\n",
    "        for tag in possible_tags:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag] if '.' in tags_df.index else 1e-6\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "            if (word, tag) not in word_prob_cache:\n",
    "                emission_p = word_given_tag(word, tag)\n",
    "                word_prob_cache[(word, tag)] = emission_p\n",
    "            else:\n",
    "                emission_p = word_prob_cache[(word, tag)]\n",
    "\n",
    "            state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "\n",
    "        pmax = max(p)\n",
    "        state_max = possible_tags[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "\n",
    "    return list(zip(words, state))\n",
    "\n",
    "# Function to compute 5-fold cross-validation, confusion matrix, and per-POS accuracy\n",
    "def evaluate_viterbi_with_cross_validation(tagged_sentences, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    all_true_tags = []\n",
    "    all_pred_tags = []\n",
    "    fold_accuracies = []\n",
    "    \n",
    "    # Prepare the transition matrix\n",
    "    tags_seq = [pair[1] for pair in tagged_words]\n",
    "    tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "    tag_list = list(tags)\n",
    "\n",
    "    for i, t1 in enumerate(tag_list):\n",
    "        for j, t2 in enumerate(tag_list):\n",
    "            tags_matrix[i, j] = t2_given_t1(t2, t1, tags_seq)\n",
    "    tags_df = pd.DataFrame(tags_matrix, columns=tag_list, index=tag_list)\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for train_index, test_index in kf.split(tagged_sentences):\n",
    "        # Split the data into train and test sets for this fold\n",
    "        train_data = [tagged_sentences[i] for i in train_index]\n",
    "        test_data = [tagged_sentences[i] for i in test_index]\n",
    "\n",
    "        # Flatten the train data for transition probability calculation\n",
    "        train_tagged_words = [tup for sent in train_data for tup in sent]\n",
    "\n",
    "        # Run Viterbi on the test set\n",
    "        for test_sent in test_data:\n",
    "            words = [word for word, tag in test_sent]\n",
    "            true_tags = [tag for word, tag in test_sent]\n",
    "            predicted_tags = [tag for word, tag in Viterbi_optimized(words, tags_df, train_tagged_words)]\n",
    "\n",
    "            all_true_tags.extend(true_tags)\n",
    "            all_pred_tags.extend(predicted_tags)\n",
    "\n",
    "        # Accuracy for the current fold\n",
    "        fold_accuracy = accuracy_score(all_true_tags, all_pred_tags)\n",
    "        fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "    # Average accuracy over the folds\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    print(f\"5-Fold Cross-Validation Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_true_tags, all_pred_tags, labels=tag_list)\n",
    "    conf_matrix_df = pd.DataFrame(conf_matrix, index=tag_list, columns=tag_list)\n",
    "    print(\"\\nConfusion Matrix:\\n\", conf_matrix_df)\n",
    "\n",
    "    # Per POS accuracy\n",
    "    per_tag_accuracy = {}\n",
    "    true_tag_counter = Counter(all_true_tags)\n",
    "\n",
    "    for tag in tag_list:\n",
    "        correct_preds = conf_matrix_df.loc[tag, tag]\n",
    "        total_true = true_tag_counter[tag]\n",
    "        per_tag_accuracy[tag] = correct_preds / total_true if total_true > 0 else 0.0\n",
    "\n",
    "    print(\"\\nPer POS Tag Accuracy:\")\n",
    "    for tag, accuracy in per_tag_accuracy.items():\n",
    "        print(f\"{tag}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "# Run the evaluation\n",
    "evaluate_viterbi_with_cross_validation(nltk_data, k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the transition matrix\n",
    "tags_seq = [pair[1] for pair in tagged_words]\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "tag_list = list(tags)\n",
    "\n",
    "for i, t1 in enumerate(tag_list):\n",
    "    for j, t2 in enumerate(tag_list):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1, tags_seq)\n",
    "tags_df = pd.DataFrame(tags_matrix, columns=tag_list, index=tag_list)\n",
    "        \n",
    "def call_viterbi(sentence):\n",
    "    words = sentence.split()\n",
    "    predicted_tags_with_words = list(Viterbi_optimized(words, tags_df, tagged_words))\n",
    "    return predicted_tags_with_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Define the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn= call_viterbi,                       # Function that processes input\n",
    "    inputs=\"text\",                       # Input type: Text field for the user\n",
    "    outputs=\"text\",                      # Output type: Text display for POS tags\n",
    "    title=\"Part-of-Speech Tagger\",       # Title of the UI\n",
    "    description=\"Enter a sentence and get the Part-of-Speech tags.\"  # Description\n",
    ")\n",
    "\n",
    "# Launch the UI in a browser\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
